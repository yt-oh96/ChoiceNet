{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ChoiceNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO/drZXFsUb2w1hW7Rg9wTH"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-rEvDt64VRWt","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"oMp2H62SpnW7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TnsBAqeMPtPg","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import math\n","import torch.nn.functional as F\n","class ChoiceNet(nn.Module):\n","  def __init__(self, feature, y_dim, num_mixture, feature_dim, logSigmaZval):\n","    self.feature = feature\n","    self.num_mixture = num_mixture\n","    self.feature_dim = feature_dim\n","    self.logSigmaZval = logSigmaZval\n","    #self.USE_GAT = USE_GAT\n","    \n","    \n","    self.fc_feauture_dim = nn.Linear(7*7*64, feature_dim)\n","    self.fc_num_mixture = nn.Linear(feature_dim,num_mixture)\n","\n","  def forward(self, x):\n","    x = self.feature(x)\n","    x = x.view(x.size(0),-1) # flatten\n","    feature = fc_feauture_dim(x)\n","    rho_raw = fc_num_mixture(feature)\n","    rho_temp = F.sigmoid(rho_raw)\n","    \n","    rho = torch.cat([rho_temp[:,0:1]*0.0 + rho_ref, rho_temp[:,1:]], axis=1)\n","\n","    Q = self.feauture_dim\n","\n","    muW = torch.nn.init.normal_(torch.empty(Q, y_dim), mean = 0.0, std = 0.1)\n","    logSigmaW = torch.nn.init.constant_(torch.empty(Q, y_dim), -3.0)\n","    \n","    myZ = torch.zeros(Q,y_dim)\n","    logSigmaZ = torch.nn.init.constant_(torch.empty(Q, y_dim), self.logSigmaZval)\n","\n","    N = x.size()[0]\n","    \n","    muW_tile = tile(muW[None], 0, N)\n","    sigmaW_tile = torch.exp(tile(logSigmaW[None], 0, N))\n","\n","    muZ_tile = tile(muZ[None], 0, N)\n","    sigmaZ_tile = torch.exp(tile(logSigmaZ[None], 0 ,N))\n","\n","    \n","\n","    #muW_tile = \n","def make_layers(self, in_channels, h_dim, filter_size, max_pools, activation, batch_norm =False):\n","    layers = []\n","\n","    #mnist\n","    for h_idx in range(len(h_dim)):\n","      fs = filter_size[h_idx]\n","      hidden = h_dim[h_idx]\n","      conv2d = nn.Conv2d(in_channels, hidden, kernel_size = fs, padding = 1)\n","      if batch_norm:\n","        layers += [conv2d, nn.BatchNorm2d(hidden), nn.ReLU()]\n","      else:\n","        layers += [conv2d, nn.ReLU()]\n","      in_channels = hidden\n","     \n","      max_pool = max_pools[h_idx]\n","      if max_pool > 1:\n","        layers += [nn.Maxpool2d(max_pool, max_pool)]\n","    return nn.Sequential(*layers)\n","\n","def tile(a, dim, n_tile):\n","    init_dim = a.size(dim)\n","    repeat_idx = [1] * a.dim()\n","    repeat_idx[dim] = n_tile\n","    a = a.repeat(*(repeat_idx))\n","    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n","    return torch.index_select(a, dim, order_index)\n","\n","def ChoiceNet_Mnist():\n","  return ChoiceNet(make_layers(in_channels, h_dim, filter_size, max_pools, activation, batch_norm ),\n","                   num_mixture)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0ChmT6jPyXN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}