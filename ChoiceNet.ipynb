{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ChoiceNet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMI8rt/Xeo9lzVioahh325k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-rEvDt64VRWt","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"TnsBAqeMPtPg","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import math\n","import torch.nn.functional as F\n","import argparse\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import math\n","\n","class ChoiceNet(nn.Module):\n","  def __init__(self, backbone, y_dim, num_mixture, feature_dim, logSigmaZval, tau_inv, pi1_bias):\n","    super(ChoiceNet,self).__init__()\n","    self.backbone = backbone\n","    self.y_dim = y_dim\n","    self.num_mixture = num_mixture\n","    self.feature_dim = feature_dim\n","    self.logSigmaZval = logSigmaZval\n","    self.tau_inv = tau_inv\n","    self.pi1_bias = pi1_bias\n","    self.rho_ref = 1\n","    #self.USE_GAT = USE_GAT\n","    \n","    \n","    self.fc_feature_dim = nn.Linear(7*7*64, self.feature_dim)\n","    self.fc_num_mixture = nn.Linear(self.feature_dim, num_mixture)\n","\n","    self.fc_var_raw = nn.Linear(self.feature_dim, self.y_dim)\n","\n","    self.fc_pi_logits = nn.Linear(self.feature_dim, self.num_mixture)\n","\n","  def forward(self, x):\n","    x = self.backbone(x)\n","    x = x.view(x.size(0),-1) # flatten\n","    self.feature = self.fc_feature_dim(x) # feature, h\n","    #print(self.feature.size())\n","    \n","    rho_raw = self.fc_num_mixture(self.feature)\n","    rho_temp = F.sigmoid(rho_raw)\n","    rho = torch.cat([rho_temp[:, 0:1]*0.0 + self.rho_ref, rho_temp[:, 1:]], axis=1) # rho(h)=rho1~rhoK, rho_ref=1\n","\n","    Q = self.feature_dim\n","    num_data = x.size()[0]\n","\n","    #make_sample\n","    muW_tile, muZ_tile, sigmaW_tile, sigmaZ_tile = self.make_sample(Q, num_data) \n","    \n","    # cholesky #[K*N*Q*D] #W_bar\n","    #branch_2\n","    samplerList = self.cholesky(self.num_mixture, Q, rho, num_data, muW_tile, sigmaW_tile, muZ_tile, sigmaZ_tile)\n","    wSample = samplerList.permute(1,3,0,2) #[N*D*K*Q]\n","\n","    #K mean mixtures\n","    wTemp = wSample.contiguous().view(num_data, self.num_mixture*self.y_dim, Q)\n","    featRsh = self.feature.view(num_data, Q, 1)\n","    _mu = torch.matmul(wTemp, featRsh) #[N*DK*1]\n","    mu = _mu.view(num_data, self.y_dim, self.num_mixture)\n","\n","    ### Add bias to mu (after)\n","\n","    #K var mixtures #(6) \n","    #branch_3\n","    logvar_raw = self.fc_var_raw(self.feature) #[N*D]\n","    var_raw = torch.exp(logvar_raw)\n","    var_tile = var_raw.unsqueeze(-1).repeat(1, 1, self.num_mixture) #N*D*K\n","    rho_tile = rho.unsqueeze(1).repeat(1, self.y_dim, 1)#N,D,K\n","    tau_inv = self.tau_inv\n","    var = (1.0 - torch.pow(rho_tile,2))*var_tile + tau_inv\n","\n","    # Weight allocation probability pi [N*K] # pi_k = softmax()_k\n","    #branch_1\n","    pi_logits = self.fc_pi_logits(self.feature) #[N*K]\n","    pi_temp = F.softmax(pi_logits, dim=1)\n","    pi_temp = torch.cat((pi_temp[:, 0:1] + self.pi1_bias, pi_temp[:, 1:]), axis=1)\n","    pi = F.softmax(pi_temp, dim=1)\n","\n","    return rho, mu, var, pi\n","    \n","  def make_sample(self, Q, num_data):\n","    N = num_data\n","\n","    muW = torch.nn.init.normal_(torch.empty(Q, self.y_dim), mean = 0.0, std = 0.1)\n","    #muW = torch.normal(std=0.1,size=(Q, self.y_dim)) # Q*D\n","    logSigmaW = torch.nn.init.constant_(torch.empty(Q, self.y_dim), -3.0)\n","    \n","    muZ = torch.zeros(Q, self.y_dim) # Q*D\n","    logSigmaZ = torch.nn.init.constant_(torch.empty(Q, self.y_dim), self.logSigmaZval)\n","    \n","    muW_tile = muW.unsqueeze(0).repeat(N,1,1) # N*Q*D\n","    sigmaW_tile = torch.exp(logSigmaW.unsqueeze(0).repeat(N,1,1)) #N*Q*D\n","    \n","    muZ_tile = muZ.unsqueeze(0).repeat(N,1,1)\n","    sigmaZ_tile = torch.exp(logSigmaZ.unsqueeze(0).repeat(N,1,1))\n","\n","    return muW_tile, muZ_tile, sigmaW_tile, sigmaZ_tile\n","\n","  def cholesky(self, num_mixture, Q, rho, num_data, muW_tile, sigmaW_tile, muZ_tile, sigmaZ_tile):\n","    samplerList = []\n","    for mix_idx in range(self.num_mixture):\n","      rho_j = rho[:, mix_idx : mix_idx+1] # N*1\n","      rho_tile = rho_j.unsqueeze(-1).repeat(1, Q, self.y_dim) # N*Q*D\n","      \n","      epsW = torch.randn(num_data, Q, self.y_dim, dtype=torch.float) #mean=0, std=1\n","      W = muW_tile + torch.sqrt(sigmaW_tile)*epsW\n","      \n","      epsZ = torch.randn(num_data, Q, self.y_dim, dtype=torch.float)\n","      Z = muZ_tile + torch.sqrt(sigmaZ_tile)*epsZ\n","\n","      #Cholesky\n","      Y = rho_tile*muW_tile + (1.0 - torch.pow(rho_tile,2))\\\n","                               *(rho_tile*torch.sqrt(sigmaZ_tile)/torch.sqrt(sigmaW_tile)\\\n","                                 *(W - muW_tile) + Z*torch.sqrt(1 - torch.pow(rho_tile,2)))\n","      \n","      samplerList.append(Y)\n","    return torch.stack(samplerList)\n","\n","\n","    #muW_tile = \n","\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wo9tzqTC_Ql4","colab_type":"code","colab":{}},"source":["def make_layers(in_channels, h_dim, filter_size, max_pools, activation, batch_norm =False):\n","    layers = []\n","\n","    #mnist\n","    for h_idx in range(len(h_dim)):\n","      fs = filter_size[h_idx]\n","      hidden = h_dim[h_idx]\n","      conv2d = nn.Conv2d(in_channels, hidden, kernel_size = fs, padding = 1)\n","      if batch_norm:\n","        layers += [conv2d, nn.BatchNorm2d(hidden), activation]\n","      else:\n","        layers += [conv2d, activation]\n","      in_channels = hidden\n","     \n","      max_pool = max_pools[h_idx]\n","      if max_pool > 1:\n","        layers += [nn.MaxPool2d(max_pool)]\n","    return nn.Sequential(*layers)\n","\n","\n","def ChoiceNet_Mnist():\n","  return ChoiceNet(make_layers(in_channels, h_dim, filter_size, max_pools, activation, batch_norm ),\n","                   y_dim, num_mixture, feature_dim, logSigmaZval, tau_inv, pi1_bias)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OQJTMfZ3cBiC","colab_type":"code","colab":{}},"source":["def train(epoch):\n","  model.train()\n","  for batch_idx, (data,target) in enumerate(train_loader):\n","    if args['cuda']:\n","      data, target = data.cuda(), target.cuda()\n","    \n","    temp = torch.LongTensor(1000,1).random_() % 10\n","    y_onehot = torch.FloatTensor(1000,10)\n","\n","    y_onehot.zero_()\n","    y_onehot.scatter_(1, temp, 1)\n","    \n","    data, target = Variable(data), Variable(y_onehot)\n","    \n","    #GRAD_CLIP = True, USE_SGD = False\n","\n","    optimizer.zero_grad()\n","\n","    rho, mu, var, pi = model(data)\n","\n","    loss, acc = MDNloss(len(data), rho, mu, var, pi, target, y_dim=10, num_mixture=10, logsumexp_coef= 1e-2, kl_reg_coef= 1e-4).forward()\n","    loss.requires_grad=True\n","    loss.backward()\n","\n","    #print(acc)\n","\n","    optimizer.step()\n","\n","    if batch_idx%args['log_interval'] == 0:\n","      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","          epoch, batch_idx * len(data), len(train_loader.dataset),\n","          100. *batch_idx/len(train_loader), loss.data\n","      ))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zS3dvJTbGQ_G","colab_type":"code","colab":{}},"source":["def test():\n","  model.eval()\n","  test_loss = 0\n","  correct = 0\n","  for data,target in test_loader:\n","    if args['cuda']:\n","      data, target = data.cuda(), target.cuda()\n","    \n","    temp = torch.LongTensor(1000,1).random_() % 10\n","    y_onehot = torch.FloatTensor(1000,10)\n","\n","    y_onehot.zero_()\n","    y_onehot.scatter_(1, temp, 1)\n","    \n","    data, target = Variable(data), Variable(y_onehot)\n","\n","    rho, mu, var, pi = model(data)\n","\n","    loss , acc = MDNloss(len(data), rho, mu, var, pi, target, y_dim=10, num_mixture=10, logsumexp_coef= 1e-2, kl_reg_coef= 1e-4).forward()\n","    test_loss += loss\n","    correct += acc#accuracy(pi,mu, len(data) ,target, y_dim=10)\n","  \n","  loss /= len(test_loader.dataset)\n","  print('\\nTest set : Average loss : {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","      loss, correct, len(test_loader.dataset),\n","      100.*correct/len(test_loader.dataset)))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jZCQU8K4nsCp","colab_type":"code","colab":{}},"source":["\n","class MDNloss(nn.Module):\n","  def __init__(self, num_data, rho, mu, var, pi, target, y_dim, num_mixture, logsumexp_coef, kl_reg_coef):\n","    super(MDNloss, self).__init__()\n","    self.num_data = num_data\n","    self.rho = Variable(rho) #N*K\n","    self.mu = Variable(mu) #N*D*K\n","    self.var = Variable(var) #N*D*K\n","    self.pi = Variable(pi) #N*K\n","    self.target = Variable(target)\n","    self.y_dim = y_dim\n","    self.num_mixture = num_mixture\n","    self.logsumexp_coef = logsumexp_coef\n","    self.kl_reg_coef = kl_reg_coef\n","\n","    self.yhat = self.mu + torch.sqrt(self.var)*torch.randn(self.num_data, self.y_dim, self.num_mixture)\n","\n","  def forward(self):\n","    target_tile = self.target.unsqueeze(-1).repeat(1, 1, self.num_mixture)# N*D*K\n","    pi_tile = self.pi.unsqueeze(1).repeat(1, self.y_dim, 1) # N*D*K\n","\n","    yhat_normalized = F.softmax(self.yhat, dim=1)\n","    _loss_fit = torch.sum(-pi_tile*yhat_normalized*target_tile, axis=[1,2])\n","    loss_fit = torch.mean(_loss_fit)\n","\n","    _loss_reg = self.pi*torch.logsumexp(self.yhat,axis=[1])\n","    __loss_reg = torch.sum(_loss_reg,axis=[1])\n","    loss_reg = self.logsumexp_coef*torch.mean(__loss_reg)\n","\n","    _eps = 1e-8\n","    _kl_reg = self.kl_reg_coef*torch.sum(self.rho*(torch.log(self.pi+_eps) - torch.log(self.rho+_eps)), axis=1)\n","    kl_reg = torch.mean(_kl_reg)\n","    # prob = self.pi*self.g_p(self.var,self.mu,self.target)\n","    # nll = -torch.log(torch.sum(prob,dim=1))\n","\n","    acc = self.acc()\n"," \n","    return torch.mean(loss_fit + loss_reg + kl_reg), acc\n","\n","  def acc(self):\n","    y = self.yhat[:,:,0] #N*D\n","    #print('y',torch.argmax(y,dim=1))\n","    #print('target',torch.argmax(self.target,dim=1))\n","    acc = (torch.argmax(y,dim=1) == torch.argmax(self.target,dim=1)).sum().item()/y.size()[0]\n","    print(acc)\n","    return acc\n","    #self.target #N*D\n","\n","\n","    \n","''' \n","\n","def accuracy(pi,mu, N ,target, y_dim):\n","  max_idx = torch.argmax(pi, axis=1)#n\n","  max_idx = 0*torch.ones_like(max_idx)\n","\n","  _mesh = torch.meshgrid(torch.arange(0,y_dim), torch.arange(0,N)) \n","  mesh = [_mesh[1], _mesh[0]]\n","  coords = torch.stack([torch.transpose(gv,1,0) for gv in mesh]+  # N,D,2\n","                       [max_idx.unsqueeze(-1).repeat(1, y_dim).view(N, y_dim)], axis=2)\n","  #mu_bar = torch.Tensor(mu, coords)\n","  #print(mu)\n","  mu_bar = mu[:,:,:1]#n,d,10      n,d,3\n","  _corr = torch.equal(torch.argmax(mu_bar, 1), torch.argmax(target, 1))   #n,d=>n\n","  corr = torch.sum(torch.argmax(mu_bar, 1) == torch.argmax(target, 1))\n","  return corr/N\n","''' \n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WgsBQTzolR0y","colab_type":"code","colab":{}},"source":["args = {}\n","kwargs = {}\n","args['batch_size'] = 1000\n","args['test_batch_size'] = 1000\n","args['epochs'] = 10\n","args['lr'] = 0.01\n","args['momentum'] = 0.5\n","\n","args['seed'] = 1\n","args['log_interval'] = 10\n","args['cuda'] = False\n","\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                   transform=transforms.Compose([\n","                                                 transforms.ToTensor(),\n","                                                 transforms.Normalize((0.1307,), (0.3081,))\n","                   ])),\n","                   batch_size = args['batch_size'], shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, download=True,\n","                   transform=transforms.Compose([\n","                                                 transforms.ToTensor(),\n","                                                 transforms.Normalize((0.1307,), (0.3081,))\n","                   ])),\n","                   batch_size = args['test_batch_size'], shuffle=True, **kwargs)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"knTcmtjD_uGe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"5513d41b-fca1-41ad-a51b-9769a2b5bbe0","executionInfo":{"status":"error","timestamp":1586105511805,"user_tz":-540,"elapsed":260505,"user":{"displayName":"‍오영택[ 대학원석·박사통합과정휴학 / 인공지능학과 ]","photoUrl":"","userId":"14804494411714270071"}}},"source":["\n","model = ChoiceNet(make_layers(in_channels=1, h_dim=[64,64], filter_size=[3,3], max_pools=[2,2], activation=torch.nn.ReLU(), batch_norm=True ),y_dim=10, num_mixture=10, feature_dim=256, logSigmaZval=-2, tau_inv=1e-4, pi1_bias=0.0)\n","\n","optimizer = optim.Adam(model.parameters(), lr=args['lr'], weight_decay=1e-5)\n","\n","for epoch in range(1, args['epochs']+1):\n","  train(epoch)\n","  test()"],"execution_count":35,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["0.101\n","Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.051168\n","0.094\n","0.095\n","0.086\n","0.107\n","0.099\n","0.09\n","0.113\n","0.11\n","0.109\n","0.107\n","Train Epoch: 1 [10000/60000 (17%)]\tLoss: -0.051912\n","0.095\n","0.104\n","0.099\n","0.092\n","0.088\n","0.095\n","0.127\n","0.095\n","0.095\n","0.103\n","Train Epoch: 1 [20000/60000 (33%)]\tLoss: -0.049683\n","0.096\n","0.103\n","0.096\n","0.096\n","0.098\n","0.112\n","0.075\n","0.105\n","0.093\n","0.107\n","Train Epoch: 1 [30000/60000 (50%)]\tLoss: -0.051849\n","0.117\n","0.117\n","0.084\n","0.109\n","0.096\n","0.085\n","0.089\n","0.11\n","0.1\n","0.113\n","Train Epoch: 1 [40000/60000 (67%)]\tLoss: -0.057564\n","0.089\n","0.1\n","0.083\n","0.099\n","0.09\n","0.107\n","0.09\n","0.092\n","0.092\n","0.082\n","Train Epoch: 1 [50000/60000 (83%)]\tLoss: -0.053170\n","0.096\n","0.102\n","0.087\n","0.1\n","0.092\n","0.105\n","0.105\n","0.078\n","0.107\n","0.098\n","0.094\n","0.114\n","0.102\n","0.098\n","0.114\n","0.086\n","0.114\n","0.095\n","0.108\n","\n","Test set : Average loss : -0.0000, Accuracy: 1.023/10000 (0%)\n","\n","0.112\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: -0.054253\n","0.093\n","0.12\n","0.099\n","0.108\n","0.102\n","0.119\n","0.09\n","0.091\n","0.095\n","0.09\n","Train Epoch: 2 [10000/60000 (17%)]\tLoss: -0.052368\n","0.114\n","0.106\n","0.09\n","0.085\n","0.097\n","0.119\n","0.089\n","0.095\n","0.117\n","0.104\n","Train Epoch: 2 [20000/60000 (33%)]\tLoss: -0.054166\n","0.133\n","0.086\n","0.099\n","0.104\n","0.098\n","0.087\n","0.103\n","0.109\n","0.1\n","0.114\n","Train Epoch: 2 [30000/60000 (50%)]\tLoss: -0.054494\n","0.097\n","0.082\n","0.106\n","0.099\n","0.115\n","0.1\n","0.094\n","0.104\n","0.094\n","0.097\n","Train Epoch: 2 [40000/60000 (67%)]\tLoss: -0.055012\n","0.099\n","0.107\n","0.11\n","0.092\n","0.101\n","0.104\n","0.113\n","0.106\n","0.104\n","0.104\n","Train Epoch: 2 [50000/60000 (83%)]\tLoss: -0.056999\n","0.101\n","0.105\n","0.124\n","0.089\n","0.108\n","0.115\n","0.09\n","0.1\n","0.086\n","0.114\n","0.095\n","0.094\n","0.081\n","0.092\n","0.104\n","0.111\n","0.117\n","0.098\n","0.096\n","\n","Test set : Average loss : -0.0000, Accuracy: 1.002/10000 (0%)\n","\n","0.114\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: -0.059015\n","0.103\n","0.13\n","0.105\n","0.108\n","0.113\n","0.096\n","0.091\n","0.115\n","0.111\n","0.109\n","Train Epoch: 3 [10000/60000 (17%)]\tLoss: -0.053965\n","0.117\n","0.116\n","0.081\n","0.103\n","0.099\n","0.086\n","0.09\n","0.099\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-0e50b9b9c420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-d5bb1e406d50>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMDNloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_mixture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogsumexp_coef\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_reg_coef\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-e8dd0f8d2f54>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_feature_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# feature, h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"om-5ajgB8pHY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}